{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, precision_recall_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from pathlib import Path\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roc_data = {}\n",
    "all_prc_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator for running a function on multiple dataset splits\n",
    "def run_on_splits(func):\n",
    "    def _run_loop(model, splits, **kwargs):\n",
    "        results = {}\n",
    "        roc_data = {}\n",
    "        prc_data = {}\n",
    "        test_roc_data = {}\n",
    "        test_prc_data = {}\n",
    "        model_name = kwargs.get('model_name', 'model')\n",
    "        for split in splits:\n",
    "            X, y, nsplit = split\n",
    "            result, roc_info, prc_info = func(model, X, y, nsplit, **kwargs)\n",
    "            results[nsplit] = result\n",
    "            roc_data[nsplit] = roc_info\n",
    "            prc_data[nsplit] = prc_info\n",
    "            if nsplit == 'test':\n",
    "                test_roc_data = {model_name: roc_info}\n",
    "                test_prc_data = {model_name: prc_info}\n",
    "        return results, roc_data, prc_data, test_roc_data, test_prc_data\n",
    "    return _run_loop\n",
    "\n",
    "@run_on_splits\n",
    "def evaluate_classification(model, X, y, nsplit, model_name):\n",
    "    preds = model.predict(X)\n",
    "    pred_probs = model.predict_proba(X)[:, 1]\n",
    "    accuracy = accuracy_score(y, preds)\n",
    "    roc_auc = roc_auc_score(y, pred_probs)\n",
    "    fpr, tpr, _ = roc_curve(y, pred_probs)\n",
    "    precision, recall, _ = precision_recall_curve(y, pred_probs)\n",
    "    prc_auc = auc(recall, precision)\n",
    "    report = classification_report(y, preds, output_dict=True)\n",
    "    print(f\"{model_name} - {nsplit} - Accuracy: {accuracy}, ROC_AUC: {roc_auc}, PRC_AUC: {prc_auc}\\n{report}\")\n",
    "    return (accuracy, report), (fpr, tpr, roc_auc), (precision, recall, prc_auc)\n",
    "\n",
    "def save_model_results(results, model_name, results_dir):\n",
    "    directory = results_dir\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    filepath = os.path.join(directory, f'{model_name}_results.txt')\n",
    "    with open(filepath, 'w') as f:\n",
    "        for split, (accuracy, report) in results.items():\n",
    "            f.write(f\"{model_name} - {split} - Accuracy: {accuracy}\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            for key, value in report.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def plot_feature_importances(model, model_name, feature_names, results_dir, filename='feature_importances.png'):\n",
    "    feature_importances = model.feature_importances_\n",
    "    indices = np.argsort(feature_importances)[-10:]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    full_path = os.path.join(results_dir, f'{model_name}_{filename}')\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "    \n",
    "def plot_roc_curves(roc_data, model_name, results_dir, filename='roc_curves.png'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for split, (fpr, tpr, roc_auc) in roc_data.items():\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} - {split} (ROC AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    full_path = os.path.join(results_dir, f'{model_name}_{filename}')\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_prc_curves(prc_data, model_name, results_dir, filename='prc_curves.png'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for split, (precision, recall, prc_auc) in prc_data.items():\n",
    "        plt.plot(recall, precision, label=f'{model_name} - {split} (PRC AUC = {prc_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    full_path = os.path.join(results_dir, f'{model_name}_{filename}')\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_combined_roc_curves(all_roc_data, results_dir, filename='all_roc_curves.png'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for model_name, (fpr, tpr, roc_auc) in all_roc_data.items():\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (ROC AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Combined ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    full_path = os.path.join(results_dir, filename)\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_combined_prc_curves(all_prc_data, results_dir, filename='all_prc_curves.png'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for model_name, prc_data in all_prc_data.items():\n",
    "        precision, recall, prc_auc = prc_data\n",
    "        plt.plot(recall, precision, label=f'{model_name} (PRC AUC = {prc_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Combined Precision-Recall Curves')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    full_path = os.path.join(results_dir, filename)\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    train_data_path = data_dir / \"train.csv\"\n",
    "    val_data_path = data_dir / \"val.csv\"\n",
    "    test_data_path = data_dir / \"test.csv\"\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    X_train = train_data.iloc[:, :-1].values\n",
    "    y_train = train_data.iloc[:, -1].values\n",
    "    X_val = val_data.iloc[:, :-1].values\n",
    "    y_val = val_data.iloc[:, -1].values\n",
    "    X_test = test_data.iloc[:, :-1].values\n",
    "    y_test = test_data.iloc[:, -1].values\n",
    "    feature_names = train_data.columns[:-1]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deterministic_model(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    \n",
    "    # calculate predictions for the deterministic model\n",
    "    def deterministic_predict(X):\n",
    "        sum_non_outcome = np.sum(X, axis=1)\n",
    "        difference = 1 - sum_non_outcome\n",
    "        return (difference >= 0.01).astype(int)\n",
    "\n",
    "    splits = [\n",
    "        (X_train, y_train, 'train'),\n",
    "        (X_val, y_val, 'val'),\n",
    "        (X_test, y_test, 'test')\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    roc_data = {}\n",
    "    prc_data = {}\n",
    "    test_roc_data = {}\n",
    "    test_prc_data = {}\n",
    "\n",
    "    for X, y, nsplit in splits:\n",
    "        preds = deterministic_predict(X)\n",
    "        pred_probs = preds  # Since it's deterministic, we use the binary predictions\n",
    "        accuracy = accuracy_score(y, preds)\n",
    "        roc_auc = roc_auc_score(y, pred_probs)\n",
    "        fpr, tpr, _ = roc_curve(y, pred_probs)\n",
    "        precision, recall, _ = precision_recall_curve(y, pred_probs)\n",
    "        prc_auc = auc(recall, precision)\n",
    "        report = classification_report(y, preds, output_dict=True)\n",
    "        print(f\"Deterministic - {nsplit} - Accuracy: {accuracy}, ROC_AUC: {roc_auc}, PRC_AUC: {prc_auc}\\n{report}\")\n",
    "        results[nsplit] = (accuracy, report)\n",
    "        roc_data[nsplit] = (fpr, tpr, roc_auc)\n",
    "        prc_data[nsplit] = (precision, recall, prc_auc)\n",
    "        if nsplit == 'test':\n",
    "            test_roc_data = {\"Deterministic\": (fpr, tpr, roc_auc)}\n",
    "            test_prc_data = {\"Deterministic\": (precision, recall, prc_auc)}\n",
    "\n",
    "    save_model_results(results, \"Deterministic\", results_dir)\n",
    "    plot_roc_curves(roc_data, \"Deterministic\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(prc_data, \"Deterministic\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"Deterministic\"] = test_roc_data[\"Deterministic\"]\n",
    "    all_prc_data[\"Deterministic\"] = test_prc_data[\"Deterministic\"]\n",
    "\n",
    "    return results, roc_data, prc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate_rf(X_train, y_train, X_val, y_val, X_test, y_test, feature_names, results_dir):\n",
    "    # Basic Random Forest model\n",
    "    basic_rfc = RandomForestClassifier(random_state=42)\n",
    "    basic_rfc.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    basic_results, basic_roc_data, basic_prc_data, test_roc_data, test_prc_data = evaluate_classification(basic_rfc, splits, model_name=\"Random_Forest_Basic\")\n",
    "    save_model_results(basic_results, \"Random_Forest_Basic\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(basic_roc_data, \"Random_Forest_Basic\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(basic_prc_data, \"Random_Forest_Basic\", results_dir, filename='prc_curves.png')\n",
    "    plot_feature_importances(basic_rfc, \"Random_Forest_Basic\", feature_names, results_dir, filename='feature_importances.png')\n",
    "\n",
    "    all_roc_data[\"Random_Forest_Basic\"] = test_roc_data[\"Random_Forest_Basic\"]\n",
    "    all_prc_data[\"Random_Forest_Basic\"] = test_prc_data[\"Random_Forest_Basic\"]\n",
    "\n",
    "    # Hyperparameter-tuned Random Forest model\n",
    "    rfc = RandomForestClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    cv_rfc = RandomizedSearchCV(estimator=rfc, param_distributions=param_grid, scoring='accuracy', n_iter=10, cv=3, random_state=42)\n",
    "    cv_rfc.fit(X_train, y_train)\n",
    "    best_params = cv_rfc.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "\n",
    "    results, roc_data, prc_data, test_roc_data, test_prc_data = evaluate_classification(cv_rfc.best_estimator_, splits, model_name=\"Random_Forest_Optimized\")\n",
    "    save_model_results(results, \"Random_Forest_Optimized\", results_dir)\n",
    "\n",
    "    plot_roc_curves(roc_data, \"Random_Forest_Optimized\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(prc_data, \"Random_Forest_Optimized\", results_dir, filename='prc_curves.png')\n",
    "    plot_feature_importances(cv_rfc.best_estimator_, \"Random_Forest_Optimized\", feature_names, results_dir, filename='feature_importances.png')\n",
    "\n",
    "    all_roc_data[\"Random_Forest_Optimized\"] = test_roc_data[\"Random_Forest_Optimized\"]\n",
    "    all_prc_data[\"Random_Forest_Optimized\"] = test_prc_data[\"Random_Forest_Optimized\"]\n",
    "\n",
    "    return results, roc_data, prc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_clf_hyperparameters(clf, param_grid, X_train, y_train):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    clf_grid = GridSearchCV(clf, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    print(\"Best hyperparameters:\\n\", clf_grid.best_params_)\n",
    "    return clf_grid.best_estimator_\n",
    "\n",
    "def tune_and_evaluate_xgboost(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # Basic XGBoost model\n",
    "    basic_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "    basic_model.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    basic_results, basic_roc_data, basic_prc_data, test_roc_data, test_prc_data = evaluate_classification(basic_model, splits, model_name=\"XGBoost_Basic\")\n",
    "    save_model_results(basic_results, \"XGBoost_Basic\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(basic_roc_data, \"XGBoost_Basic\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(basic_prc_data, \"XGBoost_Basic\", results_dir, filename='prc_curves.png')\n",
    "    \n",
    "    all_roc_data[\"XGBoost_Basic\"] = test_roc_data[\"XGBoost_Basic\"]\n",
    "    all_prc_data[\"XGBoost_Basic\"] = test_prc_data[\"XGBoost_Basic\"]\n",
    "\n",
    "    # Hyperparameter-tuned XGBoost model\n",
    "    xgb_param_grid = {\n",
    "        'max_depth': range(3, 10, 2),\n",
    "        'min_child_weight': range(1, 6, 2),\n",
    "        'learning_rate': [0.0001, 0.01, 0.1],\n",
    "        'n_estimators': [50, 200]\n",
    "    }\n",
    "    xgb_clf = xgb.XGBClassifier(random_state=0)\n",
    "    xgb_opt = tune_clf_hyperparameters(xgb_clf, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "    results, roc_data, prc_data, test_roc_data, test_prc_data = evaluate_classification(xgb_opt, splits, model_name=\"XGBoost_Optimized\")\n",
    "    save_model_results(results, \"XGBoost_Optimized\", results_dir)\n",
    "\n",
    "    plot_roc_curves(roc_data, \"XGBoost_Optimized\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(prc_data, \"XGBoost_Optimized\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"XGBoost_Optimized\"] = test_roc_data[\"XGBoost_Optimized\"]\n",
    "    all_prc_data[\"XGBoost_Optimized\"] = test_prc_data[\"XGBoost_Optimized\"]\n",
    "\n",
    "    return results, roc_data, prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess data for SVM (with imputation)\n",
    "def preprocess_data_for_svm(X_train, X_val, X_test):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    return X_train_imputed, X_val_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate_svm(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # Train a basic SVM model\n",
    "    basic_svm = SVC(probability=True, random_state=42)\n",
    "    basic_svm.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    basic_results, basic_roc_data, basic_prc_data, test_roc_data, test_prc_data = evaluate_classification(basic_svm, splits, model_name=\"SVM_Basic\")\n",
    "    save_model_results(basic_results, \"SVM_Basic\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(basic_roc_data, \"SVM_Basic\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(basic_prc_data, \"SVM_Basic\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"SVM_Basic\"] = test_roc_data[\"SVM_Basic\"]\n",
    "    all_prc_data[\"SVM_Basic\"] = test_prc_data[\"SVM_Basic\"]\n",
    "\n",
    "    # Hyperparameter-tuned SVM model\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "    cv_svm = GridSearchCV(estimator=svm, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    cv_svm.fit(X_train, y_train)\n",
    "    best_params = cv_svm.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "\n",
    "    results, roc_data, prc_data, test_roc_data, test_prc_data = evaluate_classification(cv_svm.best_estimator_, splits, model_name=\"SVM_Optimized\")\n",
    "    save_model_results(results, \"SVM_Optimized\", results_dir)\n",
    "\n",
    "    plot_roc_curves(roc_data, \"SVM_Optimized\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(prc_data, \"SVM_Optimized\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"SVM_Optimized\"] = test_roc_data[\"SVM_Optimized\"]\n",
    "    all_prc_data[\"SVM_Optimized\"] = test_prc_data[\"SVM_Optimized\"]\n",
    "\n",
    "    return results, roc_data, prc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate_neural_network(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # Define the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model, i.e., define the loss function and the optimizer\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print('Neural Network Test accuracy:', test_acc)\n",
    "\n",
    "    # Prepare results for consistency, this step is to compare with other models\n",
    "    test_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    test_pred_probs = model.predict(X_test).flatten()\n",
    "    test_report = classification_report(y_test, test_predictions, output_dict=True)\n",
    "\n",
    "    # Calculate ROC and PRC data\n",
    "    fpr, tpr, _ = roc_curve(y_test, test_pred_probs)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, test_pred_probs)\n",
    "    roc_auc = roc_auc_score(y_test, test_pred_probs)\n",
    "    prc_auc = auc(recall, precision)\n",
    "\n",
    "    results = {\n",
    "        'train': ('Not Evaluated', {}),\n",
    "        'val': ('Not Evaluated', {}),\n",
    "        'test': (test_acc, test_report)\n",
    "    }\n",
    "    save_model_results(results, \"Neural_Network\", results_dir)\n",
    "\n",
    "    # Store ROC and PRC data for the test set\n",
    "    test_roc_data = {\"Neural_Network\": (fpr, tpr, roc_auc)}\n",
    "    test_prc_data = {\"Neural_Network\": (precision, recall, prc_auc)}\n",
    "\n",
    "    all_roc_data[\"Neural_Network\"] = test_roc_data[\"Neural_Network\"]\n",
    "    all_prc_data[\"Neural_Network\"] = test_prc_data[\"Neural_Network\"]\n",
    "\n",
    "    # Plot ROC and PRC curves\n",
    "    plot_roc_curves(test_roc_data, \"Neural_Network\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(test_prc_data, \"Neural_Network\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    return results, test_roc_data, test_prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # train a basic Logistic Regression model\n",
    "    basic_lr = LogisticRegression(random_state=42, max_iter=10000)\n",
    "    basic_lr.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    basic_results, basic_roc_data, basic_prc_data, test_roc_data, test_prc_data = evaluate_classification(basic_lr, splits, model_name=\"Logistic_Regression_Basic\")\n",
    "    save_model_results(basic_results, \"Logistic_Regression_Basic\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(basic_roc_data, \"Logistic_Regression_Basic\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(basic_prc_data, \"Logistic_Regression_Basic\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"Logistic_Regression_Basic\"] = test_roc_data[\"Logistic_Regression_Basic\"]\n",
    "    all_prc_data[\"Logistic_Regression_Basic\"] = test_prc_data[\"Logistic_Regression_Basic\"]\n",
    "\n",
    "    return basic_results, basic_roc_data, basic_prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_elastic_net_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # train an Elastic Net Logistic Regression model\n",
    "    elastic_net_lr = LogisticRegressionCV(cv=5, penalty='elasticnet', solver='saga', l1_ratios=[0.5], random_state=42, max_iter=10000)\n",
    "    elastic_net_lr.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    enet_results, enet_roc_data, enet_prc_data, test_roc_data, test_prc_data = evaluate_classification(elastic_net_lr, splits, model_name=\"Elastic_Net_Logistic_Regression\")\n",
    "    save_model_results(enet_results, \"Elastic_Net_Logistic_Regression\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(enet_roc_data, \"Elastic_Net_Logistic_Regression\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(enet_prc_data, \"Elastic_Net_Logistic_Regression\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"Elastic_Net_Logistic_Regression\"] = test_roc_data[\"Elastic_Net_Logistic_Regression\"]\n",
    "    all_prc_data[\"Elastic_Net_Logistic_Regression\"] = test_prc_data[\"Elastic_Net_Logistic_Regression\"]\n",
    "\n",
    "    return enet_results, enet_roc_data, enet_prc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_majority_class_classifier(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # train a dummy classifier that predicts the majority class\n",
    "    majority_class_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "    majority_class_clf.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    majority_results, majority_roc_data, majority_prc_data, test_roc_data, test_prc_data = evaluate_classification(majority_class_clf, splits, model_name=\"Majority_Class_Classifier\")\n",
    "    save_model_results(majority_results, \"Majority_Class_Classifier\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(majority_roc_data, \"Majority_Class_Classifier\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(majority_prc_data, \"Majority_Class_Classifier\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"Majority_Class_Classifier\"] = test_roc_data[\"Majority_Class_Classifier\"]\n",
    "    all_prc_data[\"Majority_Class_Classifier\"] = test_prc_data[\"Majority_Class_Classifier\"]\n",
    "\n",
    "    return majority_results, majority_roc_data, majority_prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Chance_Class_Classifier(X_train, y_train, X_val, y_val, X_test, y_test, results_dir):\n",
    "    # train a dummy classifier that predicts a random class\n",
    "    random_class_clf = DummyClassifier(strategy='uniform', random_state=42)\n",
    "    random_class_clf.fit(X_train, y_train)\n",
    "    \n",
    "    splits = [(X_train, y_train, 'train'), (X_val, y_val, 'val'), (X_test, y_test, 'test')]\n",
    "    random_results, random_roc_data, random_prc_data, test_roc_data, test_prc_data = evaluate_classification(random_class_clf, splits, model_name=\"Chance_Class_Classifier\")\n",
    "    save_model_results(random_results, \"Chance_Class_Classifier\", results_dir)\n",
    "    \n",
    "    plot_roc_curves(random_roc_data, \"Chance_Class_Classifier\", results_dir, filename='roc_curves.png')\n",
    "    plot_prc_curves(random_prc_data, \"Chance_Class_Classifier\", results_dir, filename='prc_curves.png')\n",
    "\n",
    "    all_roc_data[\"Chance_Class_Classifier\"] = test_roc_data[\"Chance_Class_Classifier\"]\n",
    "    all_prc_data[\"Chance_Class_Classifier\"] = test_prc_data[\"Chance_Class_Classifier\"]\n",
    "\n",
    "    return random_results, random_roc_data, random_prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(data_dir, results_dir):\n",
    "    global all_roc_data, all_prc_data\n",
    "    all_roc_data = {}\n",
    "    all_prc_data = {}\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, feature_names = load_data(data_dir)\n",
    "    \n",
    "    # create a separate directory for this dataset's results\n",
    "    dataset_name = data_dir.stem\n",
    "    dataset_results_dir = results_dir / dataset_name\n",
    "    os.makedirs(dataset_results_dir, exist_ok=True)\n",
    "    \n",
    "    # Deterministic Model (skip if from 'baseline_demographic' folder)\n",
    "    if \"baseline_demographic\" not in str(data_dir):\n",
    "        deterministic_results, deterministic_roc_data, deterministic_prc_data = evaluate_deterministic_model(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "\n",
    "    # Random Forest\n",
    "    results_rf, roc_data_rf, prc_data_rf = tune_and_evaluate_rf(X_train, y_train, X_val, y_val, X_test, y_test, feature_names, dataset_results_dir)\n",
    "    \n",
    "    # XGBoost\n",
    "    results_xgb, roc_data_xgb, prc_data_xgb = tune_and_evaluate_xgboost(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Neural Network\n",
    "    results_nn, roc_data_nn, prc_data_nn = tune_and_evaluate_neural_network(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    basic_results, basic_roc_data, basic_prc_data = evaluate_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Elastic Net Logistic Regression\n",
    "    enet_results, enet_roc_data, enet_prc_data = evaluate_elastic_net_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Majority Class Classifier\n",
    "    majority_results, majority_roc_data, majority_prc_data = evaluate_majority_class_classifier(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Random Class Classifier\n",
    "    random_results, random_roc_data, random_prc_data = evaluate_Chance_Class_Classifier(X_train, y_train, X_val, y_val, X_test, y_test, dataset_results_dir)\n",
    "    \n",
    "    # Plot combined PRC and ROC curves for all models for the current dataset\n",
    "    plot_combined_prc_curves(all_prc_data, dataset_results_dir, filename='all_prc_curves.png')\n",
    "    plot_combined_roc_curves(all_roc_data, dataset_results_dir, filename='all_roc_curves.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Training Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "0    1585\n",
      "1    1583\n",
      "Name: count, dtype: int64\n",
      "Unique values: [1 0]\n",
      "Baseline Validation Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "0    359\n",
      "1    321\n",
      "Name: count, dtype: int64\n",
      "Unique values: [0 1]\n",
      "Baseline Test Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "0    348\n",
      "1    332\n",
      "Name: count, dtype: int64\n",
      "Unique values: [0 1]\n",
      "-------------------------------------------------------------------\n",
      "Real Training Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "0    1938\n",
      "1    1912\n",
      "Name: count, dtype: int64\n",
      "Unique values: [1 0]\n",
      "Real Validation Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "1    421\n",
      "0    405\n",
      "Name: count, dtype: int64\n",
      "Unique values: [1 0]\n",
      "Real Test Dataset Lacto_Binary Counts:\n",
      "Lacto_Binary\n",
      "0    433\n",
      "1    393\n",
      "Name: count, dtype: int64\n",
      "Unique values: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# ------ OBS THIS IS JUST TO CHECK THAT THE DIFFERENT DATA SETS ARE COMPATIBLE (SO Y IS 0/1 INT AND NOT FLOATS)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd().parents[1]\n",
    "\n",
    "# Function to load datasets and ensure integer type for Lacto_Binary\n",
    "def load_and_verify(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['Lacto_Binary'] = data['Lacto_Binary'].astype(int)  # Ensure integer type\n",
    "    return data\n",
    "\n",
    "# BASELINE DATA \n",
    "baseline_path_train = root / 'data' / 'baseline_demographic' / 'train.csv'\n",
    "baseline_path_val = root / 'data' / 'baseline_demographic' / 'val.csv'\n",
    "baseline_path_test = root / 'data' / 'baseline_demographic' / 'test.csv'\n",
    "\n",
    "# For the training dataset\n",
    "train_data_baseline = load_and_verify(baseline_path_train)\n",
    "print(\"Baseline Training Dataset Lacto_Binary Counts:\")\n",
    "print(train_data_baseline['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", train_data_baseline['Lacto_Binary'].unique())\n",
    "\n",
    "# For the validation dataset\n",
    "val_data_baseline = load_and_verify(baseline_path_val)\n",
    "print(\"Baseline Validation Dataset Lacto_Binary Counts:\")\n",
    "print(val_data_baseline['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", val_data_baseline['Lacto_Binary'].unique())\n",
    "\n",
    "# For the test dataset\n",
    "test_data_baseline = load_and_verify(baseline_path_test)\n",
    "print(\"Baseline Test Dataset Lacto_Binary Counts:\")\n",
    "print(test_data_baseline['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", test_data_baseline['Lacto_Binary'].unique())\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "# REAL DATA \n",
    "path_train = root / 'data' / 'reduced_0_1' / 'train.csv'\n",
    "path_val = root / 'data' / 'reduced_0_1' / 'val.csv'\n",
    "path_test = root / 'data' / 'reduced_0_1' / 'test.csv'\n",
    "\n",
    "# For the training dataset\n",
    "train_data_real = load_and_verify(path_train)\n",
    "print(\"Real Training Dataset Lacto_Binary Counts:\")\n",
    "print(train_data_real['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", train_data_real['Lacto_Binary'].unique())\n",
    "\n",
    "# For the validation dataset\n",
    "val_data_real = load_and_verify(path_val)\n",
    "print(\"Real Validation Dataset Lacto_Binary Counts:\")\n",
    "print(val_data_real['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", val_data_real['Lacto_Binary'].unique())\n",
    "\n",
    "# For the test dataset\n",
    "test_data_real = load_and_verify(path_test)\n",
    "print(\"Real Test Dataset Lacto_Binary Counts:\")\n",
    "print(test_data_real['Lacto_Binary'].value_counts())\n",
    "print(\"Unique values:\", test_data_real['Lacto_Binary'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic - train - Accuracy: 0.5033766233766234, ROC_AUC: 0.5, PRC_AUC: 0.7483116883116883\n",
      "{'0.0': {'precision': 0.5033766233766234, 'recall': 1.0, 'f1-score': 0.6696613683483068, 'support': 1938.0}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1912.0}, 'accuracy': 0.5033766233766234, 'macro avg': {'precision': 0.2516883116883117, 'recall': 0.5, 'f1-score': 0.3348306841741534, 'support': 3850.0}, 'weighted avg': {'precision': 0.25338802496205093, 'recall': 0.5033766233766234, 'f1-score': 0.3370918784049399, 'support': 3850.0}}\n",
      "Deterministic - val - Accuracy: 0.49031476997578693, ROC_AUC: 0.5, PRC_AUC: 0.7548426150121066\n",
      "{'0.0': {'precision': 0.49031476997578693, 'recall': 1.0, 'f1-score': 0.6580016246953696, 'support': 405.0}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 421.0}, 'accuracy': 0.49031476997578693, 'macro avg': {'precision': 0.24515738498789347, 'recall': 0.5, 'f1-score': 0.3290008123476848, 'support': 826.0}, 'weighted avg': {'precision': 0.24040857365640886, 'recall': 0.49031476997578693, 'f1-score': 0.3226279152562042, 'support': 826.0}}\n",
      "Deterministic - test - Accuracy: 0.5254237288135594, ROC_AUC: 0.5012722646310432, PRC_AUC: 0.7385604002242636\n",
      "{'0.0': {'precision': 0.5248484848484849, 'recall': 1.0, 'f1-score': 0.6883942766295708, 'support': 433.0}, '1.0': {'precision': 1.0, 'recall': 0.002544529262086514, 'f1-score': 0.005076142131979695, 'support': 393.0}, 'accuracy': 0.5254237288135594, 'macro avg': {'precision': 0.7624242424242424, 'recall': 0.5012722646310432, 'f1-score': 0.34673520938077523, 'support': 826.0}, 'weighted avg': {'precision': 0.750919363122753, 'recall': 0.5254237288135594, 'f1-score': 0.36328044266158854, 'support': 826.0}}\n",
      "Random_Forest_Basic - train - Accuracy: 1.0, ROC_AUC: 1.0, PRC_AUC: 1.0\n",
      "{'0.0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1938.0}, '1.0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1912.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3850.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3850.0}}\n",
      "Random_Forest_Basic - val - Accuracy: 0.7542372881355932, ROC_AUC: 0.8446203923638603, PRC_AUC: 0.8630728357677558\n",
      "{'0.0': {'precision': 0.7186147186147186, 'recall': 0.8197530864197531, 'f1-score': 0.7658592848904268, 'support': 405.0}, '1.0': {'precision': 0.7994505494505495, 'recall': 0.6912114014251781, 'f1-score': 0.7414012738853503, 'support': 421.0}, 'accuracy': 0.7542372881355932, 'macro avg': {'precision': 0.7590326340326341, 'recall': 0.7554822439224655, 'f1-score': 0.7536302793878885, 'support': 826.0}, 'weighted avg': {'precision': 0.7598155476484775, 'recall': 0.7542372881355932, 'f1-score': 0.7533933979253696, 'support': 826.0}}\n",
      "Random_Forest_Basic - test - Accuracy: 0.7542372881355932, ROC_AUC: 0.8363068478982658, PRC_AUC: 0.8308522011491056\n",
      "{'0.0': {'precision': 0.7649769585253456, 'recall': 0.766743648960739, 'f1-score': 0.7658592848904268, 'support': 433.0}, '1.0': {'precision': 0.7423469387755102, 'recall': 0.7404580152671756, 'f1-score': 0.7414012738853503, 'support': 393.0}, 'accuracy': 0.7542372881355932, 'macro avg': {'precision': 0.7536619486504279, 'recall': 0.7536008321139573, 'f1-score': 0.7536302793878885, 'support': 826.0}, 'weighted avg': {'precision': 0.754209891017252, 'recall': 0.7542372881355932, 'f1-score': 0.7542224830441857, 'support': 826.0}}\n",
      "Best parameters: {'n_estimators': 50, 'min_samples_split': 2, 'max_features': None, 'max_depth': 10}\n",
      "Random_Forest_Optimized - train - Accuracy: 0.9394805194805195, ROC_AUC: 0.9854816789080751, PRC_AUC: 0.9870549584091212\n",
      "{'0.0': {'precision': 0.9290387518872673, 'recall': 0.9525283797729618, 'f1-score': 0.9406369426751592, 'support': 1938.0}, '1.0': {'precision': 0.9506172839506173, 'recall': 0.926255230125523, 'f1-score': 0.9382781456953643, 'support': 1912.0}, 'accuracy': 0.9394805194805195, 'macro avg': {'precision': 0.9398280179189422, 'recall': 0.9393918049492425, 'f1-score': 0.9394575441852617, 'support': 3850.0}, 'weighted avg': {'precision': 0.9397551553431439, 'recall': 0.9394805194805195, 'f1-score': 0.9394655089542844, 'support': 3850.0}}\n",
      "Random_Forest_Optimized - val - Accuracy: 0.7639225181598063, ROC_AUC: 0.8599894431248352, PRC_AUC: 0.8755789629971937\n",
      "{'0.0': {'precision': 0.7375565610859729, 'recall': 0.8049382716049382, 'f1-score': 0.7697756788665879, 'support': 405.0}, '1.0': {'precision': 0.7942708333333334, 'recall': 0.7244655581947743, 'f1-score': 0.7577639751552795, 'support': 421.0}, 'accuracy': 0.7639225181598063, 'macro avg': {'precision': 0.7659136972096532, 'recall': 0.7647019148998563, 'f1-score': 0.7637698270109337, 'support': 826.0}, 'weighted avg': {'precision': 0.7664629879820247, 'recall': 0.7639225181598063, 'f1-score': 0.763653490897507, 'support': 826.0}}\n",
      "Random_Forest_Optimized - test - Accuracy: 0.7651331719128329, ROC_AUC: 0.8421627911076636, PRC_AUC: 0.8500791734135541\n",
      "{'0.0': {'precision': 0.7907542579075426, 'recall': 0.7505773672055427, 'f1-score': 0.7701421800947867, 'support': 433.0}, '1.0': {'precision': 0.7397590361445783, 'recall': 0.7811704834605598, 'f1-score': 0.7599009900990099, 'support': 393.0}, 'accuracy': 0.7651331719128329, 'macro avg': {'precision': 0.7652566470260604, 'recall': 0.7658739253330513, 'f1-score': 0.7650215850968983, 'support': 826.0}, 'weighted avg': {'precision': 0.7664913981583357, 'recall': 0.7651331719128329, 'f1-score': 0.7652695557989752, 'support': 826.0}}\n",
      "XGBoost_Basic - train - Accuracy: 1.0, ROC_AUC: 1.0, PRC_AUC: 1.0\n",
      "{'0.0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1938.0}, '1.0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1912.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3850.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3850.0}}\n",
      "XGBoost_Basic - val - Accuracy: 0.7699757869249395, ROC_AUC: 0.8494061757719715, PRC_AUC: 0.8671529264971365\n",
      "{'0.0': {'precision': 0.7437641723356009, 'recall': 0.8098765432098766, 'f1-score': 0.7754137115839244, 'support': 405.0}, '1.0': {'precision': 0.8, 'recall': 0.7315914489311164, 'f1-score': 0.7642679900744417, 'support': 421.0}, 'accuracy': 0.7699757869249395, 'macro avg': {'precision': 0.7718820861678004, 'recall': 0.7707339960704964, 'f1-score': 0.769840850829183, 'support': 826.0}, 'weighted avg': {'precision': 0.7724267430943322, 'recall': 0.7699757869249395, 'f1-score': 0.7697329019525779, 'support': 826.0}}\n",
      "XGBoost_Basic - test - Accuracy: 0.7542372881355932, ROC_AUC: 0.8429502435813809, PRC_AUC: 0.8494512444221407\n",
      "{'0.0': {'precision': 0.7725118483412322, 'recall': 0.7528868360277137, 'f1-score': 0.7625730994152047, 'support': 433.0}, '1.0': {'precision': 0.7351485148514851, 'recall': 0.7557251908396947, 'f1-score': 0.7452948557089084, 'support': 393.0}, 'accuracy': 0.7542372881355932, 'macro avg': {'precision': 0.7538301815963586, 'recall': 0.7543060134337042, 'f1-score': 0.7539339775620566, 'support': 826.0}, 'weighted avg': {'precision': 0.7547348627946577, 'recall': 0.7542372881355932, 'f1-score': 0.7543523369738314, 'support': 826.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 50}\n",
      "XGBoost_Optimized - train - Accuracy: 0.8631168831168832, ROC_AUC: 0.9430159203077839, PRC_AUC: 0.9479392783145983\n",
      "{'0.0': {'precision': 0.8518703241895261, 'recall': 0.8813209494324046, 'f1-score': 0.8663454222673092, 'support': 1938.0}, '1.0': {'precision': 0.8753387533875339, 'recall': 0.8446652719665272, 'f1-score': 0.8597285067873304, 'support': 1912.0}, 'accuracy': 0.8631168831168832, 'macro avg': {'precision': 0.86360453878853, 'recall': 0.8629931106994659, 'f1-score': 0.8630369645273197, 'support': 3850.0}, 'weighted avg': {'precision': 0.8635252947418873, 'recall': 0.8631168831168832, 'f1-score': 0.8630593073588106, 'support': 3850.0}}\n",
      "XGBoost_Optimized - val - Accuracy: 0.7760290556900726, ROC_AUC: 0.8640860971819008, PRC_AUC: 0.8760349252832931\n",
      "{'0.0': {'precision': 0.748868778280543, 'recall': 0.817283950617284, 'f1-score': 0.781582054309327, 'support': 405.0}, '1.0': {'precision': 0.8072916666666666, 'recall': 0.7363420427553444, 'f1-score': 0.7701863354037267, 'support': 421.0}, 'accuracy': 0.7760290556900726, 'macro avg': {'precision': 0.7780802224736048, 'recall': 0.7768129966863142, 'f1-score': 0.7758841948565269, 'support': 826.0}, 'weighted avg': {'precision': 0.7786460615863033, 'recall': 0.7760290556900726, 'f1-score': 0.7757738246976349, 'support': 826.0}}\n",
      "XGBoost_Optimized - test - Accuracy: 0.7578692493946732, ROC_AUC: 0.845676944684402, PRC_AUC: 0.851545710236254\n",
      "{'0.0': {'precision': 0.7807228915662651, 'recall': 0.7482678983833718, 'f1-score': 0.7641509433962265, 'support': 433.0}, '1.0': {'precision': 0.7347931873479319, 'recall': 0.7684478371501272, 'f1-score': 0.7512437810945274, 'support': 393.0}, 'accuracy': 0.7578692493946732, 'macro avg': {'precision': 0.7577580394570984, 'recall': 0.7583578677667495, 'f1-score': 0.7576973622453769, 'support': 826.0}, 'weighted avg': {'precision': 0.7588701388328452, 'recall': 0.7578692493946732, 'f1-score': 0.7580098843350064, 'support': 826.0}}\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmaolsen/Desktop/MB-LM-24/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 0.8257 - val_accuracy: 0.6259 - val_loss: 0.6617\n",
      "Epoch 2/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6581 - loss: 0.6268 - val_accuracy: 0.6308 - val_loss: 0.6357\n",
      "Epoch 3/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.6875 - loss: 0.5793 - val_accuracy: 0.6368 - val_loss: 0.6528\n",
      "Epoch 4/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7066 - loss: 0.5591 - val_accuracy: 0.6513 - val_loss: 0.6313\n",
      "Epoch 5/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7121 - loss: 0.5483 - val_accuracy: 0.6465 - val_loss: 0.6270\n",
      "Epoch 6/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7412 - loss: 0.5139 - val_accuracy: 0.6683 - val_loss: 0.6180\n",
      "Epoch 7/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7513 - loss: 0.4972 - val_accuracy: 0.6441 - val_loss: 0.6499\n",
      "Epoch 8/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7664 - loss: 0.4806 - val_accuracy: 0.6683 - val_loss: 0.6263\n",
      "Epoch 9/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7913 - loss: 0.4495 - val_accuracy: 0.6513 - val_loss: 0.6578\n",
      "Epoch 10/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7865 - loss: 0.4620 - val_accuracy: 0.6586 - val_loss: 0.6377\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.6639 - loss: 0.6733\n",
      "Neural Network Test accuracy: 0.685230016708374\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step\n",
      "Logistic_Regression_Basic - train - Accuracy: 0.7236363636363636, ROC_AUC: 0.7969745154172658, PRC_AUC: 0.802692361411887\n",
      "{'0.0': {'precision': 0.7006427915518825, 'recall': 0.7874097007223942, 'f1-score': 0.7414965986394558, 'support': 1938.0}, '1.0': {'precision': 0.7535885167464115, 'recall': 0.6589958158995816, 'f1-score': 0.703125, 'support': 1912.0}, 'accuracy': 0.7236363636363636, 'macro avg': {'precision': 0.727115654149147, 'recall': 0.7232027583109879, 'f1-score': 0.722310799319728, 'support': 3850.0}, 'weighted avg': {'precision': 0.7269368763757628, 'recall': 0.7236363636363636, 'f1-score': 0.7224403657566923, 'support': 3850.0}}\n",
      "Logistic_Regression_Basic - val - Accuracy: 0.6828087167070218, ROC_AUC: 0.7662004046802148, PRC_AUC: 0.7937539122828237\n",
      "{'0.0': {'precision': 0.6505263157894737, 'recall': 0.762962962962963, 'f1-score': 0.7022727272727273, 'support': 405.0}, '1.0': {'precision': 0.7264957264957265, 'recall': 0.6057007125890737, 'f1-score': 0.6606217616580311, 'support': 421.0}, 'accuracy': 0.6828087167070218, 'macro avg': {'precision': 0.6885110211426001, 'recall': 0.6843318377760184, 'f1-score': 0.6814472444653792, 'support': 826.0}, 'weighted avg': {'precision': 0.6892468023600941, 'recall': 0.6828087167070218, 'f1-score': 0.6810438452826703, 'support': 826.0}}\n",
      "Logistic_Regression_Basic - test - Accuracy: 0.7203389830508474, ROC_AUC: 0.7933583672701843, PRC_AUC: 0.7943126329181229\n",
      "{'0.0': {'precision': 0.7186147186147186, 'recall': 0.766743648960739, 'f1-score': 0.7418994413407821, 'support': 433.0}, '1.0': {'precision': 0.7225274725274725, 'recall': 0.6692111959287532, 'f1-score': 0.6948480845442536, 'support': 393.0}, 'accuracy': 0.7203389830508474, 'macro avg': {'precision': 0.7205710955710956, 'recall': 0.7179774224447462, 'f1-score': 0.7183737629425179, 'support': 826.0}, 'weighted avg': {'precision': 0.7204763557669126, 'recall': 0.7203389830508474, 'f1-score': 0.7195130209763322, 'support': 826.0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    root = Path.cwd().parents[1]\n",
    "    data_dirs = [root / \"data\" / \"reduced_0_1\", root / \"data\" / \"reduced_0_1_PCA\", root / \"data\" / \"reduced_0_1_SVD\", root / \"data\" / \"baseline_demographic\",root / \"data\" / \"non_reduced\"]\n",
    "    results_dir = root / \"results\" / \"model_reports\"\n",
    "    for data_dir in data_dirs:\n",
    "        run_all_models(data_dir, results_dir)\n",
    "\n",
    "# run the main function using \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
